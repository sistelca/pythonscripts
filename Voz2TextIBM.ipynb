{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to install pyaudio to run this example\n",
    "# pip install pyaudio\n",
    "\n",
    "# When using a microphone, the AudioSource `input` parameter would be\n",
    "# initialised as a queue. The pyaudio stream would be continuosly adding\n",
    "# recordings to the queue, and the websocket client would be sending the\n",
    "# recordings to the speech to text service\n",
    "\n",
    "import pyaudio\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
    "from threading import Thread\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "try:\n",
    "    from Queue import Queue, Full\n",
    "except ImportError:\n",
    "    from queue import Queue, Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#### Initalize queue to store the recordings ##\n",
    "###############################################\n",
    "CHUNK = 1024\n",
    "# Note: It will discard if the websocket client can't consumme fast enough\n",
    "# So, increase the max size as per your choice\n",
    "BUF_MAX_SIZE = CHUNK * 10\n",
    "# Buffer to store audio\n",
    "q = Queue(maxsize=int(round(BUF_MAX_SIZE / CHUNK)))\n",
    "\n",
    "# Create an instance of AudioSource\n",
    "audio_source = AudioSource(q, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('mkhyHog-CXPGHjU66CXYvGbQieTDoKfbIWUCPSDNPyJT')\n",
    "speech_to_text = SpeechToTextV1(authenticator=authenticator)\n",
    "speech_to_text.set_service_url('wss://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/a54f0700-47ab-4d6f-a319-bad474a85c09/v1/recognize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#### Prepare Speech to Text Service ########\n",
    "###############################################\n",
    "\n",
    "# initialize speech to text service\n",
    "\n",
    "key_ser = 'dAQo_RUpjKu9L7dJA3gIGr0AzWNsiyhUXh62cbvu_hTz'\n",
    "url = 'https://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/80503afd-ede9-44e0-953f-69161242eba1'\n",
    "\n",
    "\n",
    "authenticator = IAMAuthenticator(key_ser)\n",
    "speech_to_text = SpeechToTextV1(authenticator=authenticator)\n",
    "\n",
    "speech_to_text.set_service_url(url)\n",
    "\n",
    "#wss://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/{instance_id}/v1/recognize\n",
    "\n",
    "#speech_to_text.set_service_url('https://stream.watsonplatform.net/speech-to-text/api')\n",
    "\n",
    "# define callback for the speech to text service\n",
    "class MyRecognizeCallback(RecognizeCallback):\n",
    "    def __init__(self):\n",
    "        RecognizeCallback.__init__(self)\n",
    "\n",
    "    def on_transcription(self, transcript):\n",
    "        print(transcript)\n",
    "\n",
    "    def on_connected(self):\n",
    "        print('Connection was successful')\n",
    "\n",
    "    def on_error(self, error):\n",
    "        print('Error received: {}'.format(error))\n",
    "\n",
    "    def on_inactivity_timeout(self, error):\n",
    "        print('Inactivity timeout: {}'.format(error))\n",
    "\n",
    "    def on_listening(self):\n",
    "        print('Service is listening')\n",
    "\n",
    "    def on_hypothesis(self, hypothesis):\n",
    "        print(hypothesis)\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(data)\n",
    "\n",
    "    def on_close(self):\n",
    "        print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will initiate the recognize service and pass in the AudioSource\n",
    "def recognize_using_weboscket(*args):\n",
    "    mycallback = MyRecognizeCallback()\n",
    "    speech_to_text.recognize_using_websocket(audio=audio_source,\n",
    "                                             content_type='audio/l16; rate=44100',\n",
    "                                             recognize_callback=mycallback,\n",
    "                                             interim_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#### Prepare the for recording using Pyaudio ##\n",
    "###############################################\n",
    "\n",
    "# Variables for recording the speech\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "\n",
    "# define callback for pyaudio to store the recording in queue\n",
    "def pyaudio_callback(in_data, frame_count, time_info, status):\n",
    "    try:\n",
    "        q.put(in_data)\n",
    "    except Full:\n",
    "        pass # discard\n",
    "    return (None, pyaudio.paContinue)\n",
    "\n",
    "# instantiate pyaudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# open stream using callback\n",
    "stream = audio.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    "    stream_callback=pyaudio_callback,\n",
    "    start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter CTRL+C to end recording...\n",
      "Connection was successful\n",
      "Service is listening\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#### Start the recording and start service to recognize the stream ######\n",
    "#########################################################################\n",
    "\n",
    "print(\"Enter CTRL+C to end recording...\")\n",
    "stream.start_stream()\n",
    "\n",
    "try:\n",
    "    recognize_thread = Thread(target=recognize_using_weboscket, args=())\n",
    "    recognize_thread.start()\n",
    "\n",
    "    while True:\n",
    "        pass\n",
    "except KeyboardInterrupt:\n",
    "    # stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    audio_source.completed_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
