{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2016/10/03/bubble-sheet-multiple-choice-scanner-and-test-grader-using-omr-python-and-opencv/\n",
    "# import the necessary packages\n",
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    " \n",
    "# define the answer key which maps the question number\n",
    "# to the correct answer\n",
    "ANSWER_KEY = {0: 1, 1: 4, 2: 0, 3: 3, 4: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, blur it\n",
    "# slightly, then find edges\n",
    "image = cv2.imread('./omr_test_01.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "edged = cv2.Canny(blurred, 75, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"edged\", edged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the edges of the document are clearly defined, with all four vertices of the exam being present in the image.\n",
    "\n",
    "Obtaining this silhouette of the document is extremely important in our next step as we will use it as a marker to apply a perspective transform to the exam, obtaining a top-down, birds-eye-view of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the edge map, then initialize\n",
    "# the contour that corresponds to the document\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "docCnt = None\n",
    " \n",
    "# ensure that at least one contour was found\n",
    "if len(cnts) > 0:\n",
    "    # sort the contours according to their size in\n",
    "    # descending order\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    " \n",
    "    # loop over the sorted contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "        # if our approximated contour has four points,\n",
    "        # then we can assume we have found the paper\n",
    "        if len(approx) == 4:\n",
    "            docCnt = approx\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in cnts:\n",
    "    # compute the bounding box of the contour and then draw the\n",
    "    # bounding box on both input images to represent where the two\n",
    "    # images differ\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the outline of our exam, we apply the cv2.findContours  function to find the lines that correspond to the exam itself.\n",
    "\n",
    "We do this by sorting our contours by their area (from largest to smallest) on Line 37 (after making sure at least one contour was found on Line 34, of course). This implies that larger contours will be placed at the front of the list, while smaller contours will appear farther back in the list.\n",
    "\n",
    "We make the assumption that our exam will be the main focal point of the image, and thus be larger than other objects in the image. This assumption allows us to “filter” our contours, simply by investigating their area and knowing that the contour that corresponds to the exam should be near the front of the list.\n",
    "\n",
    "However, contour area and size is not enough — we should also check the number of vertices on the contour.\n",
    "\n",
    "To do, this, we loop over each of our (sorted) contours on Line 40. For each of them, we approximate the contour, which in essence means we simplify the number of points in the contour, making it a “more basic” geometric shape. You can read more about contour approximation in this post on building a mobile document scanner.\n",
    "\n",
    "On Line 47 we make a check to see if our approximated contour has four points, and if it does, we assume that we have found the exam.\n",
    "\n",
    "Below I have included an example image that demonstrates the docCnt  variable being drawn on the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a four point perspective transform to both the\n",
    "# original image and grayscale image to obtain a top-down\n",
    "# birds eye view of the paper\n",
    "paper = four_point_transform(image, docCnt.reshape(4, 2))\n",
    "warped = four_point_transform(gray, docCnt.reshape(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Otsu's thresholding method to binarize the warped\n",
    "# piece of paper\n",
    "thresh = cv2.threshold(warped, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"thresh\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image, then initialize\n",
    "# the list of contours that correspond to questions\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "questionCnts = []\n",
    " \n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # compute the bounding box of the contour, then use the\n",
    "    # bounding box to derive the aspect ratio\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ar = w / float(h)\n",
    " \n",
    "    # in order to label the contour as a question, region\n",
    "    # should be sufficiently wide, sufficiently tall, and\n",
    "    # have an aspect ratio approximately equal to 1\n",
    "    if w >= 20 and h >= 20 and ar >= 0.9 and ar <= 1.1:\n",
    "        questionCnts.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines 64-67 handle finding contours on our thresh  binary image, followed by initializing questionCnts , a list of contours that correspond to the questions/bubbles on the exam.\n",
    "\n",
    "To determine which regions of the image are bubbles, we first loop over each of the individual contours (Line 70).\n",
    "\n",
    "For each of these contours, we compute the bounding box (Line 73), which also allows us to compute the aspect ratio, or more simply, the ratio of the width to the height (Line 74).\n",
    "\n",
    "In order for a contour area to be considered a bubble, the region should:\n",
    "\n",
    "Be sufficiently wide and tall (in this case, at least 20 pixels in both dimensions).\n",
    "Have an aspect ratio that is approximately equal to 1.\n",
    "As long as these checks hold, we can update our questionCnts  list and mark the region as a bubble.\n",
    "\n",
    "Below I have included a screenshot that has drawn the output of questionCnts  on our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over the contours\n",
    "output = paper.copy()\n",
    "for question in questionCnts:\n",
    "    # compute the bounding box of the contour and then draw the\n",
    "    # bounding box on both input images to represent where the two\n",
    "    # images differ\n",
    "    contours_poly = cv2.approxPolyDP(question, 3, True)\n",
    "    \n",
    "    center, radiu = cv2.minEnclosingCircle(contours_poly)\n",
    "    \n",
    "    \n",
    "    cv2.circle(output, (int(center[0]), int(center[1])), int(radiu), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.imshow(\"questions\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how only the question regions of the exam are highlighted and nothing else.\n",
    "\n",
    "We can now move on to the “grading” portion of our OMR system:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the question contours top-to-bottom, then initialize\n",
    "# the total number of correct answers\n",
    "questionCnts = contours.sort_contours(questionCnts, method=\"top-to-bottom\")[0]\n",
    "correct = 0\n",
    "\n",
    "# each question has 5 possible answers, to loop over the\n",
    "# question in batches of 5\n",
    "for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):\n",
    "    # sort the contours for the current question from\n",
    "    # left to right, then initialize the index of the\n",
    "    # bubbled answer\n",
    "    cnts = contours.sort_contours(questionCnts[i:i + 5])[0]\n",
    "    bubbled = None\n",
    "    \n",
    "    # loop over the sorted contours\n",
    "    for (j, c) in enumerate(cnts):\n",
    "        # construct a mask that reveals only the current\n",
    "        # \"bubble\" for the question\n",
    "        mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        cv2.drawContours(mask, [c], -1, 255, -1)\n",
    " \n",
    "        # apply the mask to the thresholded image, then\n",
    "        # count the number of non-zero pixels in the\n",
    "        # bubble area\n",
    "        mask = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "        total = cv2.countNonZero(mask)\n",
    " \n",
    "        # if the current total has a larger number of total\n",
    "        # non-zero pixels, then we are examining the currently\n",
    "        # bubbled-in answer\n",
    "        if bubbled is None or total > bubbled[0]:\n",
    "            bubbled = (total, j)\n",
    "        \n",
    "    # initialize the contour color and the index of the\n",
    "    # *correct* answer\n",
    "    color = (0, 0, 255)\n",
    "    k = ANSWER_KEY[q]\n",
    " \n",
    "    # check to see if the bubbled answer is correct\n",
    "    if k == bubbled[1]:\n",
    "        color = (0, 255, 0)\n",
    "        correct += 1\n",
    " \n",
    "    # draw the outline of the correct answer on the test\n",
    "    cv2.drawContours(respuesta, [cnts[k]], -1, color, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"respuesta\", respuesta)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a row of bubbles, the next step is to determine which bubble is filled in.\n",
    "\n",
    "We can accomplish this by using our thresh  image and counting the number of non-zero pixels (i.e., foreground pixels) in each bubble region:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 98 handles looping over each of the sorted bubbles in the row.\n",
    "\n",
    "We then construct a mask for the current bubble on Line 101 and then count the number of non-zero pixels in the masked region (Lines 107 and 108). The more non-zero pixels we count, then the more foreground pixels there are, and therefore the bubble with the maximum non-zero count is the index of the bubble that the the test taker has bubbled in (Line 113 and 114).\n",
    "\n",
    "Below I have included an example of creating and applying a mask to each bubble associated with a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# loop over the contours\n",
    "output = paper.copy()\n",
    "colors = [(220,20,60), (255,215,0), (34,139,34), (32,178,170), (128,0,0)]\n",
    "\n",
    "i= 0\n",
    "\n",
    "for question in questionCnts:\n",
    "    \n",
    "    color = colors[i//5]\n",
    "    \n",
    "    # compute the bounding box of the contour and then draw the\n",
    "    # bounding box on both input images to represent where the two\n",
    "    # images differ\n",
    "    contours_poly = cv2.approxPolyDP(question, 3, True)\n",
    "    \n",
    "    center, radiu = cv2.minEnclosingCircle(contours_poly)\n",
    "    \n",
    "    \n",
    "    cv2.circle(output, (int(center[0]), int(center[1])), int(radiu), color, 2)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "cv2.imshow(\"questions\", output)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the bubble associated with “B” has the most thresholded pixels, and is therefore the bubble that the user has marked on their exam.\n",
    "\n",
    "This next code block handles looking up the correct answer in the ANSWER_KEY , updating any relevant bookkeeper variables, and finally drawing the marked bubble on our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"respuesta\", respuesta)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] score: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# grab the test taker\n",
    "score = (correct / 5.0) * 100\n",
    "print(\"[INFO] score: {:.2f}%\".format(score))\n",
    "cv2.putText(respuesta, \"{:.2f}%\".format(score), (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Exam\", respuesta)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[[ 81, 270]],\n",
      "\n",
      "       [[ 80, 271]],\n",
      "\n",
      "       [[ 78, 271]],\n",
      "\n",
      "       [[ 77, 272]],\n",
      "\n",
      "       [[ 76, 272]],\n",
      "\n",
      "       [[ 70, 278]],\n",
      "\n",
      "       [[ 70, 279]],\n",
      "\n",
      "       [[ 69, 280]],\n",
      "\n",
      "       [[ 69, 281]],\n",
      "\n",
      "       [[ 68, 282]],\n",
      "\n",
      "       [[ 68, 291]],\n",
      "\n",
      "       [[ 69, 292]],\n",
      "\n",
      "       [[ 69, 294]],\n",
      "\n",
      "       [[ 71, 296]],\n",
      "\n",
      "       [[ 71, 297]],\n",
      "\n",
      "       [[ 74, 300]],\n",
      "\n",
      "       [[ 75, 300]],\n",
      "\n",
      "       [[ 76, 301]],\n",
      "\n",
      "       [[ 77, 301]],\n",
      "\n",
      "       [[ 78, 302]],\n",
      "\n",
      "       [[ 79, 302]],\n",
      "\n",
      "       [[ 80, 303]],\n",
      "\n",
      "       [[ 90, 303]],\n",
      "\n",
      "       [[ 91, 302]],\n",
      "\n",
      "       [[ 92, 302]],\n",
      "\n",
      "       [[ 93, 301]],\n",
      "\n",
      "       [[ 94, 301]],\n",
      "\n",
      "       [[100, 295]],\n",
      "\n",
      "       [[100, 294]],\n",
      "\n",
      "       [[101, 293]],\n",
      "\n",
      "       [[101, 291]],\n",
      "\n",
      "       [[102, 290]],\n",
      "\n",
      "       [[102, 282]],\n",
      "\n",
      "       [[101, 281]],\n",
      "\n",
      "       [[101, 280]],\n",
      "\n",
      "       [[100, 279]],\n",
      "\n",
      "       [[100, 278]],\n",
      "\n",
      "       [[ 98, 276]],\n",
      "\n",
      "       [[ 98, 275]],\n",
      "\n",
      "       [[ 97, 274]],\n",
      "\n",
      "       [[ 96, 274]],\n",
      "\n",
      "       [[ 94, 272]],\n",
      "\n",
      "       [[ 93, 272]],\n",
      "\n",
      "       [[ 92, 271]],\n",
      "\n",
      "       [[ 90, 271]],\n",
      "\n",
      "       [[ 89, 270]]]))\n",
      "(1, array([[[126, 270]],\n",
      "\n",
      "       [[125, 271]],\n",
      "\n",
      "       [[123, 271]],\n",
      "\n",
      "       [[122, 272]],\n",
      "\n",
      "       [[121, 272]],\n",
      "\n",
      "       [[115, 278]],\n",
      "\n",
      "       [[115, 279]],\n",
      "\n",
      "       [[114, 280]],\n",
      "\n",
      "       [[114, 282]],\n",
      "\n",
      "       [[113, 283]],\n",
      "\n",
      "       [[113, 290]],\n",
      "\n",
      "       [[114, 291]],\n",
      "\n",
      "       [[114, 293]],\n",
      "\n",
      "       [[115, 294]],\n",
      "\n",
      "       [[115, 295]],\n",
      "\n",
      "       [[120, 300]],\n",
      "\n",
      "       [[121, 300]],\n",
      "\n",
      "       [[123, 302]],\n",
      "\n",
      "       [[125, 302]],\n",
      "\n",
      "       [[126, 303]],\n",
      "\n",
      "       [[134, 303]],\n",
      "\n",
      "       [[135, 302]],\n",
      "\n",
      "       [[137, 302]],\n",
      "\n",
      "       [[138, 301]],\n",
      "\n",
      "       [[139, 301]],\n",
      "\n",
      "       [[145, 295]],\n",
      "\n",
      "       [[145, 294]],\n",
      "\n",
      "       [[146, 293]],\n",
      "\n",
      "       [[146, 291]],\n",
      "\n",
      "       [[147, 290]],\n",
      "\n",
      "       [[147, 283]],\n",
      "\n",
      "       [[146, 282]],\n",
      "\n",
      "       [[146, 280]],\n",
      "\n",
      "       [[145, 279]],\n",
      "\n",
      "       [[145, 278]],\n",
      "\n",
      "       [[143, 276]],\n",
      "\n",
      "       [[143, 275]],\n",
      "\n",
      "       [[142, 274]],\n",
      "\n",
      "       [[141, 274]],\n",
      "\n",
      "       [[139, 272]],\n",
      "\n",
      "       [[138, 272]],\n",
      "\n",
      "       [[137, 271]],\n",
      "\n",
      "       [[135, 271]],\n",
      "\n",
      "       [[134, 270]]]))\n",
      "(2, array([[[171, 270]],\n",
      "\n",
      "       [[170, 271]],\n",
      "\n",
      "       [[168, 271]],\n",
      "\n",
      "       [[167, 272]],\n",
      "\n",
      "       [[166, 272]],\n",
      "\n",
      "       [[165, 273]],\n",
      "\n",
      "       [[164, 273]],\n",
      "\n",
      "       [[161, 276]],\n",
      "\n",
      "       [[161, 277]],\n",
      "\n",
      "       [[159, 279]],\n",
      "\n",
      "       [[159, 281]],\n",
      "\n",
      "       [[158, 282]],\n",
      "\n",
      "       [[158, 291]],\n",
      "\n",
      "       [[159, 292]],\n",
      "\n",
      "       [[159, 293]],\n",
      "\n",
      "       [[160, 294]],\n",
      "\n",
      "       [[160, 295]],\n",
      "\n",
      "       [[162, 297]],\n",
      "\n",
      "       [[162, 298]],\n",
      "\n",
      "       [[163, 298]],\n",
      "\n",
      "       [[166, 301]],\n",
      "\n",
      "       [[167, 301]],\n",
      "\n",
      "       [[168, 302]],\n",
      "\n",
      "       [[170, 302]],\n",
      "\n",
      "       [[171, 303]],\n",
      "\n",
      "       [[179, 303]],\n",
      "\n",
      "       [[180, 302]],\n",
      "\n",
      "       [[181, 302]],\n",
      "\n",
      "       [[182, 301]],\n",
      "\n",
      "       [[183, 301]],\n",
      "\n",
      "       [[184, 300]],\n",
      "\n",
      "       [[185, 300]],\n",
      "\n",
      "       [[189, 296]],\n",
      "\n",
      "       [[189, 295]],\n",
      "\n",
      "       [[190, 294]],\n",
      "\n",
      "       [[190, 293]],\n",
      "\n",
      "       [[191, 292]],\n",
      "\n",
      "       [[191, 290]],\n",
      "\n",
      "       [[192, 289]],\n",
      "\n",
      "       [[192, 284]],\n",
      "\n",
      "       [[191, 283]],\n",
      "\n",
      "       [[191, 280]],\n",
      "\n",
      "       [[190, 279]],\n",
      "\n",
      "       [[190, 278]],\n",
      "\n",
      "       [[184, 272]],\n",
      "\n",
      "       [[183, 272]],\n",
      "\n",
      "       [[182, 271]],\n",
      "\n",
      "       [[180, 271]],\n",
      "\n",
      "       [[179, 270]]]))\n",
      "(3, array([[[215, 270]],\n",
      "\n",
      "       [[214, 271]],\n",
      "\n",
      "       [[213, 271]],\n",
      "\n",
      "       [[212, 272]],\n",
      "\n",
      "       [[211, 272]],\n",
      "\n",
      "       [[210, 273]],\n",
      "\n",
      "       [[209, 273]],\n",
      "\n",
      "       [[206, 276]],\n",
      "\n",
      "       [[206, 277]],\n",
      "\n",
      "       [[204, 279]],\n",
      "\n",
      "       [[204, 280]],\n",
      "\n",
      "       [[203, 281]],\n",
      "\n",
      "       [[203, 292]],\n",
      "\n",
      "       [[204, 293]],\n",
      "\n",
      "       [[204, 294]],\n",
      "\n",
      "       [[205, 295]],\n",
      "\n",
      "       [[205, 296]],\n",
      "\n",
      "       [[209, 300]],\n",
      "\n",
      "       [[210, 300]],\n",
      "\n",
      "       [[211, 301]],\n",
      "\n",
      "       [[212, 301]],\n",
      "\n",
      "       [[213, 302]],\n",
      "\n",
      "       [[215, 302]],\n",
      "\n",
      "       [[216, 303]],\n",
      "\n",
      "       [[224, 303]],\n",
      "\n",
      "       [[225, 302]],\n",
      "\n",
      "       [[227, 302]],\n",
      "\n",
      "       [[229, 300]],\n",
      "\n",
      "       [[230, 300]],\n",
      "\n",
      "       [[234, 296]],\n",
      "\n",
      "       [[234, 295]],\n",
      "\n",
      "       [[236, 293]],\n",
      "\n",
      "       [[236, 291]],\n",
      "\n",
      "       [[237, 290]],\n",
      "\n",
      "       [[237, 283]],\n",
      "\n",
      "       [[236, 282]],\n",
      "\n",
      "       [[236, 280]],\n",
      "\n",
      "       [[234, 278]],\n",
      "\n",
      "       [[234, 277]],\n",
      "\n",
      "       [[230, 273]],\n",
      "\n",
      "       [[229, 273]],\n",
      "\n",
      "       [[227, 271]],\n",
      "\n",
      "       [[225, 271]],\n",
      "\n",
      "       [[224, 270]]]))\n",
      "(4, array([[[261, 270]],\n",
      "\n",
      "       [[260, 271]],\n",
      "\n",
      "       [[258, 271]],\n",
      "\n",
      "       [[257, 272]],\n",
      "\n",
      "       [[256, 272]],\n",
      "\n",
      "       [[255, 273]],\n",
      "\n",
      "       [[254, 273]],\n",
      "\n",
      "       [[251, 276]],\n",
      "\n",
      "       [[251, 277]],\n",
      "\n",
      "       [[249, 279]],\n",
      "\n",
      "       [[249, 280]],\n",
      "\n",
      "       [[248, 281]],\n",
      "\n",
      "       [[248, 285]],\n",
      "\n",
      "       [[247, 286]],\n",
      "\n",
      "       [[247, 287]],\n",
      "\n",
      "       [[248, 288]],\n",
      "\n",
      "       [[248, 291]],\n",
      "\n",
      "       [[249, 292]],\n",
      "\n",
      "       [[249, 294]],\n",
      "\n",
      "       [[251, 296]],\n",
      "\n",
      "       [[251, 297]],\n",
      "\n",
      "       [[254, 300]],\n",
      "\n",
      "       [[255, 300]],\n",
      "\n",
      "       [[257, 302]],\n",
      "\n",
      "       [[259, 302]],\n",
      "\n",
      "       [[260, 303]],\n",
      "\n",
      "       [[263, 303]],\n",
      "\n",
      "       [[264, 304]],\n",
      "\n",
      "       [[266, 304]],\n",
      "\n",
      "       [[267, 303]],\n",
      "\n",
      "       [[270, 303]],\n",
      "\n",
      "       [[271, 302]],\n",
      "\n",
      "       [[273, 302]],\n",
      "\n",
      "       [[275, 300]],\n",
      "\n",
      "       [[276, 300]],\n",
      "\n",
      "       [[279, 297]],\n",
      "\n",
      "       [[279, 296]],\n",
      "\n",
      "       [[281, 294]],\n",
      "\n",
      "       [[281, 292]],\n",
      "\n",
      "       [[282, 291]],\n",
      "\n",
      "       [[282, 284]],\n",
      "\n",
      "       [[281, 283]],\n",
      "\n",
      "       [[281, 281]],\n",
      "\n",
      "       [[280, 280]],\n",
      "\n",
      "       [[280, 279]],\n",
      "\n",
      "       [[279, 278]],\n",
      "\n",
      "       [[279, 277]],\n",
      "\n",
      "       [[275, 273]],\n",
      "\n",
      "       [[274, 273]],\n",
      "\n",
      "       [[273, 272]],\n",
      "\n",
      "       [[272, 272]],\n",
      "\n",
      "       [[271, 271]],\n",
      "\n",
      "       [[269, 271]],\n",
      "\n",
      "       [[268, 270]]]))\n"
     ]
    }
   ],
   "source": [
    "for j, c in enumerate(cnts):\n",
    "    print(j, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
